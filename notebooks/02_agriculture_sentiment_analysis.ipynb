{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "- Python 3.10.4\n",
    "\n",
    "> Warning: Installation from conda environment may take few minutes\n",
    "\n",
    "Configuring conda environment\n",
    "\n",
    "```cmd\n",
    "conda activate ca2_env\n",
    "conda install matplotlib\n",
    "conda install pandas\n",
    "conda install nltk\n",
    "conda install scikit-learn\n",
    "conda install -c conda-forge textblob\n",
    "conda install -c conda-forge tweepy\n",
    "conda install -c conda-forge pycountry\n",
    "conda install -c conda-forge wordcloud\n",
    "conda install -c conda-forge langdetect\n",
    "```\n",
    "\n",
    "References:\n",
    "https://towardsdatascience.com/step-by-step-twitter-sentiment-analysis-in-python-d6f650ade58d\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\rmsry\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('brown')\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "bearerToken = \"AAAAAAAAAAAAAAAAAAAAABoHcAEAAAAA78rV2Phg2vUbwTdcJ2QPGGji65M%3DsTr8DETODttIuwkHy9czi663YUpUPLDOVY2VqUzmBdshiJmLT3\"\n",
    "\n",
    "auth = tweepy.OAuth2BearerHandler(bearerToken)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh And #Canada #Ireland #Spain #England And #France https://t.co/rNNKqSdjjV\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "def percentage(part,whole):\n",
    " return 100 * float(part)/float(whole)\n",
    "keyword = input(\"Please enter keyword or hashtag to search: \")\n",
    "noOfTweet = int(input (\"Please enter how many tweets to analyze: \"))\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)\n",
    "    tweet_list.append(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    " \n",
    "    if neg > pos:\n",
    "        negative_list.append(tweet.text)\n",
    "        negative += 1\n",
    "    elif pos > neg:\n",
    "        positive_list.append(tweet.text)\n",
    "        positive += 1\n",
    "    elif pos == neg:\n",
    "        neutral_list.append(tweet.text)\n",
    "        neutral += 1\n",
    "\n",
    "positive = percentage(positive, noOfTweet)\n",
    "negative = percentage(negative, noOfTweet)\n",
    "neutral = percentage(neutral, noOfTweet)\n",
    "polarity = percentage(polarity, noOfTweet)\n",
    "positive = format(positive, '.1f')\n",
    "negative = format(negative, '.1f')\n",
    "neutral = format(neutral, '.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "print(\"total number: \",len(tweet_list))\n",
    "print(\"positive number: \",len(positive_list))\n",
    "print(\"negative number: \", len(negative_list))\n",
    "print(\"neutral number: \",len(neutral_list))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c336f7bfc73179085ae8f866c8f0055bc59896acda20a450ad7008a76c4aea3"
  },
  "kernelspec": {
   "display_name": "ca2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
