{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "- Python 3.10.4\n",
    "\n",
    "> Warning: Installation from conda environment may take few minutes\n",
    "\n",
    "Configuring conda environment\n",
    "\n",
    "```cmd\n",
    "conda activate ca2_env\n",
    "conda install matplotlib\n",
    "conda install pandas\n",
    "conda install nltk\n",
    "conda install scikit-learn\n",
    "conda install jsonpickle\n",
    "conda install -c conda-forge textblob\n",
    "conda install -c conda-forge scrapy\n",
    "conda install -c conda-forge pycountry\n",
    "conda install -c conda-forge wordcloud\n",
    "conda install -c conda-forge langdetect\n",
    "pip install emoji\n",
    "```\n",
    "\n",
    "References:\n",
    "https://towardsdatascience.com/step-by-step-twitter-sentiment-analysis-in-python-d6f650ade58d\n",
    "CCT College; David Text Processing Class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFA Market and prices - Web scrapage\n",
    "\n",
    "## Step 1: Configure spider\n",
    "Configure spider `\\scrapy\\quotesbot\\ifa-css.py` with the list of urls\n",
    "\n",
    "\n",
    "```python\n",
    "urls=[  'https://www.ifa.ie/markets-and-prices/grain-price-update-20th-may/',\n",
    "        'https://www.ifa.ie/markets-and-prices/potato-market-update-18th-may/',\n",
    "        'https://www.ifa.ie/markets-and-prices/pig-market-update-18th-may-2/',\n",
    "        'https://www.ifa.ie/markets-and-prices/weekly-cattle-prices-18th-may/',\n",
    "        ...\n",
    "        'https://www.ifa.ie/markets-and-prices/grain-market-update-3rd-feb/',\n",
    "        'https://www.ifa.ie/markets-and-prices/weekly-cattle-prices-3rd-feb/',\n",
    "        'https://www.ifa.ie/markets-and-prices/potato-market-update-3rd-feb/']\n",
    "```\n",
    "\n",
    "## Step 2: Check css selectors.\n",
    "The following selectors has been configured.\n",
    "\n",
    "```python\n",
    "    yield {\n",
    "        'title': quote.css(\".entry-title::text\").extract_first(),\n",
    "        'time': quote.css(\".entry-date::text\").extract_first(),\n",
    "        'text': quote.css(\".single-content > p::text\").getall()\n",
    "    }\n",
    "```\n",
    "## Step 3: Run scrapy\n",
    "Run `scrapy crawl toscrape-css -o market-prices.json` to generate markets and prices articles. See full list of URLS below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rmsry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rmsry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "# Store the string.punctuation into an object punct\n",
    "punct = string.punctuation\n",
    "\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Weekly Cattle Prices 9th March</td>\n",
       "      <td>9 March 2022</td>\n",
       "      <td>[Prices reported as quoted or paid to IFA Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Weekly Cattle Prices 6th April</td>\n",
       "      <td>6 April 2022</td>\n",
       "      <td>[Prices reported as quoted or paid to IFA Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Potato Market Update 3rd Feb</td>\n",
       "      <td>3 February 2021</td>\n",
       "      <td>[Household consumption and retail sales remain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pig Market Update 4th May</td>\n",
       "      <td>4 May 2022</td>\n",
       "      <td>[Irish pig price was unchanged this week with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Beef &amp; Sheep Update 25th June</td>\n",
       "      <td>25 June 2021</td>\n",
       "      <td>[IFA Livestock Chairman Brendan Golden said be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title             time  \\\n",
       "43   Weekly Cattle Prices 9th March     9 March 2022   \n",
       "34   Weekly Cattle Prices 6th April     6 April 2022   \n",
       "163    Potato Market Update 3rd Feb  3 February 2021   \n",
       "15        Pig Market Update 4th May       4 May 2022   \n",
       "124   Beef & Sheep Update 25th June     25 June 2021   \n",
       "\n",
       "                                                  text  \n",
       "43   [Prices reported as quoted or paid to IFA Memb...  \n",
       "34   [Prices reported as quoted or paid to IFA Memb...  \n",
       "163  [Household consumption and retail sales remain...  \n",
       "15   [Irish pig price was unchanged this week with ...  \n",
       "124  [IFA Livestock Chairman Brendan Golden said be...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_price_df = pd.read_json(\"../data/ifa.ie/market-prices.json\")\n",
    "market_price_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>text_original</th>\n",
       "      <th>tags</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>numeric_values</th>\n",
       "      <th>upper</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, time, text, text_original, tags, word_count, avg_word, stopwords, numeric_values, upper, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of original text\n",
    "market_price_df['text'] = market_price_df['text'].apply(lambda x: str(x))\n",
    "market_price_df['text_original'] = market_price_df['text']\n",
    "\n",
    "# Title of article\n",
    "market_price_df[\"title\"] = market_price_df.title.astype(str)\n",
    "market_price_df[\"tags\"] = market_price_df.title.apply(lambda x: x.split(\" Update \")[0][:15])\n",
    "\n",
    "# Original Word count\n",
    "market_price_df['word_count'] = market_price_df['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Average word length\n",
    "market_price_df['avg_word'] = market_price_df['text'].apply(lambda x: avg_word(x))\n",
    "\n",
    "# Create column with stop words on text\n",
    "market_price_df['stopwords'] = market_price_df['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "market_price_df[['text','stopwords']].head()\n",
    "\n",
    "# Number of numers in text\n",
    "market_price_df['numeric_values'] = market_price_df['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "market_price_df[['text','numeric_values']].head()\n",
    "\n",
    "# Highlight upper case words\n",
    "market_price_df['upper'] = market_price_df['text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "market_price_df[['text','upper']].head()\n",
    "\n",
    "# Convert text to lower\n",
    "market_price_df['text'] = market_price_df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "market_price_df['text'].head()\n",
    "\n",
    "# Remove stop words\n",
    "stop = stopwords.words('english')\n",
    "market_price_df['text'] = market_price_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "market_price_df['text'].head()\n",
    "\n",
    "# remove 10 most frequent words\n",
    "freq = pd.Series(' '.join(market_price_df['text']).split()).value_counts()[:10]\n",
    "freq = list(freq.index)\n",
    "market_price_df['text'] = market_price_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "market_price_df['text'].head()\n",
    "\n",
    "# remove 10 less frequet words\n",
    "freq = pd.Series(' '.join(market_price_df['text']).split()).value_counts()[-10:]\n",
    "freq = list(freq.index)\n",
    "market_price_df['text'] = market_price_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "market_price_df['text'].head()\n",
    "\n",
    "# Remove special characters\n",
    "market_price_df = market_price_df.replace(r'[^A-Za-z0-9 ]+', '', regex=True)\n",
    "\n",
    "# Get sentiment using TextBlob\n",
    "market_price_df['sentiment'] = market_price_df['text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "market_price_df.query(\"abs(sentiment) > 0.5 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Boards.ie CAP \n",
    "\n",
    "## Step 1: Configure spider\n",
    "Configure spider `\\scrapy\\quotesbot\\boards-css.py` with the list of urls. Discussion regarding CAP reforms since 2013.\n",
    "\n",
    "\n",
    "```python\n",
    "urls=[  'https://www.boards.ie/discussion/2058237577/new-cap-for-2023/p1',\n",
    "        'https://www.boards.ie/discussion/2058214934/new-cap/p1',\n",
    "        'https://www.boards.ie/discussion/2057938257/post-2020-cap/p1',\n",
    "        'https://www.boards.ie/discussion/2057780562/cap-payments-reference-years-2000-2002/p1',\n",
    "        'https://www.boards.ie/discussion/2057336158/the-new-cap/p1',\n",
    "        'https://www.boards.ie/discussion/2057111876/cap-reform/p1',\n",
    "        'https://www.boards.ie/discussion/2056998752/cap-2013/p1']\n",
    "```\n",
    "\n",
    "## Step 2: Check css selectors.\n",
    "The following selectors has been configured.\n",
    "\n",
    "```python\n",
    "    yield {\n",
    "            'title': response.css(\"#Item_0 > h1::text\").extract_first(),\n",
    "            'time_1': li.css(\"div.postbit-header::text\").extract_first(),\n",
    "            'time': li.css(\"a.Permalink::text\").extract_first(),\n",
    "            'text': li.css(\"div.Item-Body > div.Message > p::text\").getall(),\n",
    "            'text_1': li.css(\"div.Item-Body > div.Message::text\").getall()\n",
    "        }\n",
    "```\n",
    "\n",
    "\n",
    "## Step 3: Run scrapy\n",
    "Run `scrapy crawl boards-css -o market-prices.json` to generate cap discussion json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time_1</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post 2020 CAP</td>\n",
       "      <td>\\n15-12-2018 1:18pm</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\\nJust wondering what the room thinks of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post 2020 CAP</td>\n",
       "      <td>\\n</td>\n",
       "      <td>15-12-2018 1:34pm</td>\n",
       "      <td>[\\n, \\n, \\n]</td>\n",
       "      <td>[\\n, \\n, \\nThe entitlements belong to your mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Post 2020 CAP</td>\n",
       "      <td>\\n</td>\n",
       "      <td>15-12-2018 1:37pm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\\nIt's a ridiculous scheme anyway. Pure lazin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Post 2020 CAP</td>\n",
       "      <td>\\n</td>\n",
       "      <td>15-12-2018 3:19pm</td>\n",
       "      <td>[\\n, \\n, \\n]</td>\n",
       "      <td>[\\n, \\n, \\nCompletely agree ( though instinct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cap 2013</td>\n",
       "      <td>\\n23-07-2013 5:29pm</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\\nA quote from Mairead mcguinness on the perm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                time_1               time          text  \\\n",
       "0  Post 2020 CAP  \\n15-12-2018 1:18pm                None            []   \n",
       "1  Post 2020 CAP                    \\n  15-12-2018 1:34pm  [\\n, \\n, \\n]   \n",
       "2  Post 2020 CAP                    \\n  15-12-2018 1:37pm            []   \n",
       "3  Post 2020 CAP                    \\n  15-12-2018 3:19pm  [\\n, \\n, \\n]   \n",
       "4       Cap 2013  \\n23-07-2013 5:29pm                None            []   \n",
       "\n",
       "                                              text_1  \n",
       "0  [\\nJust wondering what the room thinks of the ...  \n",
       "1  [\\n, \\n, \\nThe entitlements belong to your mot...  \n",
       "2  [\\nIt's a ridiculous scheme anyway. Pure lazin...  \n",
       "3  [\\n, \\n, \\nCompletely agree ( though instinct ...  \n",
       "4  [\\nA quote from Mairead mcguinness on the perm...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_df = pd.read_json(\"../data/boards.ie/boards-cap.json\")\n",
    "cap_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge time fields\n",
    "cap_df[\"time\"] = cap_df.apply(lambda x: x.time if x.time != None and str(x.time) > str(x.time_1) else str(x.time_1).replace(\"\\\\n\",\"\"), axis=1 )\n",
    "cap_df[\"time\"] = cap_df.time.astype(np.datetime64)\n",
    "cap_df.drop(\"time_1\",inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df[\"text\"] = cap_df.apply(lambda x: str(x.text).replace(\"\\\\n\",\"\") if len(str(x.text)) > len(str(x.text_1)) else str(x.text_1).replace(\"\\\\n\",\"\"), axis=1 )\n",
    "cap_df.drop(\"text_1\",inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-27 20:40:00</td>\n",
       "      <td>['What peoples thought on leased land and enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Post 2020 CAP</td>\n",
       "      <td>2018-12-15 17:08:00</td>\n",
       "      <td>['', '', \"Completely agree, it's redicolous.\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-27 17:23:00</td>\n",
       "      <td>['', '', \"I don't know about AF as it'd be too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CAP Payments Reference Years 2000-2002</td>\n",
       "      <td>2017-08-27 19:21:00</td>\n",
       "      <td>['', '', \"It was well flagged that the link'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>New CAP for 2023</td>\n",
       "      <td>2022-03-16 16:38:00</td>\n",
       "      <td>['', '', 'Ah indeed it was a draft I got the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>New CAP for 2023</td>\n",
       "      <td>2022-03-16 18:56:00</td>\n",
       "      <td>['', '', 'Yeah just picked it as a random refe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-27 21:01:00</td>\n",
       "      <td>['', '', 'The payments follow which ever is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cap 2013</td>\n",
       "      <td>2013-07-23 18:57:00</td>\n",
       "      <td>['Good road frontage?;) ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-11-13 09:57:00</td>\n",
       "      <td>['', '', 'Depends. Dept fella said they first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-27 09:39:00</td>\n",
       "      <td>['', '', \"You can on that farmers journal calc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title                time  \\\n",
       "117                                 New CAP 2021-10-27 20:40:00   \n",
       "15                            Post 2020 CAP 2018-12-15 17:08:00   \n",
       "107                                 New CAP 2021-10-27 17:23:00   \n",
       "25   CAP Payments Reference Years 2000-2002 2017-08-27 19:21:00   \n",
       "72                         New CAP for 2023 2022-03-16 16:38:00   \n",
       "78                         New CAP for 2023 2022-03-16 18:56:00   \n",
       "124                                 New CAP 2021-10-27 21:01:00   \n",
       "17                                 Cap 2013 2013-07-23 18:57:00   \n",
       "166                                 New CAP 2021-11-13 09:57:00   \n",
       "52                                  New CAP 2021-10-27 09:39:00   \n",
       "\n",
       "                                                  text  \n",
       "117  ['What peoples thought on leased land and enti...  \n",
       "15   ['', '', \"Completely agree, it's redicolous.\",...  \n",
       "107  ['', '', \"I don't know about AF as it'd be too...  \n",
       "25   ['', '', \"It was well flagged that the link'd ...  \n",
       "72   ['', '', 'Ah indeed it was a draft I got the t...  \n",
       "78   ['', '', 'Yeah just picked it as a random refe...  \n",
       "124  ['', '', 'The payments follow which ever is th...  \n",
       "17                          ['Good road frontage?;) ']  \n",
       "166  ['', '', 'Depends. Dept fella said they first ...  \n",
       "52   ['', '', \"You can on that farmers journal calc...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling emoji's\n",
    "def replace_emoji(w:str):\n",
    "   for key in emoji.unicode_codes.EMOJI_DATA:\n",
    "      if key in w:\n",
    "         lang = emoji.unicode_codes.EMOJI_DATA.get(key)\n",
    "         w = w.replace(key,str(lang.get('en')).replace(\"_\",\" \").replace(\":\",\" \"))\n",
    "   return w\n",
    "\n",
    "def clean_word_emoji(w):\n",
    "   w = re.sub(r'[\\[A-Za-z\\]]',\"\",w)\n",
    "   w = w.replace(\"'\",\"\")\n",
    "   return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    wondering room thinks following theory widowed...\n",
       "1    entitlements belong mother leased current tena...\n",
       "2    ridiculous scheme anyway pure laziness let sit...\n",
       "3    completely agree though instinct tells phil ho...\n",
       "4    quote mairead mcguinness permanent pasture asp...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of original text\n",
    "cap_df['text_original'] = cap_df['text'].astype(\"str\")\n",
    "\n",
    "# Replace emoji with name\n",
    "cap_df['text'] = cap_df['text'].apply(lambda x: replace_emoji(x))\n",
    "\n",
    "# Original Word count\n",
    "cap_df['word_count'] = cap_df['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Average word length\n",
    "cap_df['avg_word'] = cap_df['text'].apply(lambda x: avg_word(x))\n",
    "\n",
    "# Create column with stop words\n",
    "stop = stopwords.words('english')\n",
    "cap_df['stopwords'] = cap_df['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "cap_df[['text','stopwords']].head()\n",
    "\n",
    "# Number of numers in text\n",
    "cap_df['numeric_values'] = cap_df['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "cap_df[['text','numeric_values']].head()\n",
    "\n",
    "# Highlight upper case words\n",
    "cap_df['upper'] = cap_df['text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "cap_df[['text','upper']].head()\n",
    "\n",
    "# Convert text to lower\n",
    "cap_df['text'] = cap_df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "cap_df['text'].head()\n",
    "\n",
    "# Remove stop words after text formatting\n",
    "stop = stopwords.words('english')\n",
    "cap_df['text'] = cap_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "cap_df['text'].head()\n",
    "\n",
    "# Remove puntuation\n",
    "cap_df['text'] = cap_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in punct))\n",
    "cap_df['text'].head()\n",
    "\n",
    "# remove 10 most frequent words\n",
    "freq = pd.Series(' '.join(cap_df['text']).split()).value_counts()[:10]\n",
    "freq = list(freq.index)\n",
    "cap_df['text'] = cap_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "cap_df['text'].head()\n",
    "\n",
    "# remove 10 less frequet words\n",
    "freq = pd.Series(' '.join(cap_df['text']).split()).value_counts()[-10:]\n",
    "freq = list(freq.index)\n",
    "cap_df['text'] = cap_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "cap_df['text'].head()\n",
    "\n",
    "# Remove special characters\n",
    "cap_df = cap_df.replace(r'[^A-Za-z0-9 ]+', '', regex=True)\n",
    "\n",
    "# Second pass stop words after text formatting\n",
    "stop = stopwords.words('english')\n",
    "cap_df['text'] = cap_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "cap_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentiment using TextBlob\n",
    "cap_df['sentiment'] = cap_df['text'].apply(lambda x: TextBlob(x).sentiment[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>text_original</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>numeric_values</th>\n",
       "      <th>upper</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAP Payments Reference Years 20002002</td>\n",
       "      <td>2017-08-27 18:57:00</td>\n",
       "      <td>chosen privie information others lucky</td>\n",
       "      <td>I would think the chosen few were privie to th...</td>\n",
       "      <td>16</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAP Payments Reference Years 20002002</td>\n",
       "      <td>2017-08-27 19:02:00</td>\n",
       "      <td>afairm fairly well known going reference years...</td>\n",
       "      <td>Afairm it was fairly well known there were g...</td>\n",
       "      <td>21</td>\n",
       "      <td>4.476190</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cap 2013</td>\n",
       "      <td>2013-07-23 18:57:00</td>\n",
       "      <td>good road frontage</td>\n",
       "      <td>Good road frontage</td>\n",
       "      <td>4</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-26 19:43:00</td>\n",
       "      <td>happy im farmer whats new</td>\n",
       "      <td>Not happy but then Im a farmer so whats new</td>\n",
       "      <td>13</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-26 19:47:00</td>\n",
       "      <td>convergence heading right direction done thoug...</td>\n",
       "      <td>Convergence heading in the right direction m...</td>\n",
       "      <td>53</td>\n",
       "      <td>4.698113</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.324416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-26 20:00:00</td>\n",
       "      <td>10k seems top new environmental scheme payment...</td>\n",
       "      <td>10k seems to be the top of the new environment...</td>\n",
       "      <td>87</td>\n",
       "      <td>4.321839</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.347273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>cap reform</td>\n",
       "      <td>2013-12-28 13:43:00</td>\n",
       "      <td>im guessing coincide sps 14 application period...</td>\n",
       "      <td>Im guessing it will coincide with the sps 14...</td>\n",
       "      <td>18</td>\n",
       "      <td>5.055556</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>New CAP for 2023</td>\n",
       "      <td>2022-03-16 17:16:00</td>\n",
       "      <td>ok 25 figure using calc got saying 25 suckler ...</td>\n",
       "      <td>OK so is the 25 figure youre using in that cal...</td>\n",
       "      <td>23</td>\n",
       "      <td>3.695652</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>New CAP for 2023</td>\n",
       "      <td>2022-03-16 17:18:00</td>\n",
       "      <td>reference number ie best 3 years averagedlets ...</td>\n",
       "      <td>Is it not the reference number ie your best 3 ...</td>\n",
       "      <td>38</td>\n",
       "      <td>5.026316</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>New CAP for 2023</td>\n",
       "      <td>2022-03-16 20:38:00</td>\n",
       "      <td>ah ok thanks</td>\n",
       "      <td>ah ok thanks</td>\n",
       "      <td>5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>New CAP for 2023</td>\n",
       "      <td>2022-03-17 16:12:00</td>\n",
       "      <td>endainoz good truemy understanding based princ...</td>\n",
       "      <td>Endainoz I think that would be to good to be t...</td>\n",
       "      <td>62</td>\n",
       "      <td>5.725806</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>New CAP for 2023</td>\n",
       "      <td>2022-03-18 20:13:00</td>\n",
       "      <td>tree planting anyone got information many tree...</td>\n",
       "      <td>Tree planting Anyone got any information on ho...</td>\n",
       "      <td>17</td>\n",
       "      <td>4.588235</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-27 12:59:00</td>\n",
       "      <td>quick one agroforestry count towards eco schem...</td>\n",
       "      <td>Just quick one Will agroforestry count towards...</td>\n",
       "      <td>16</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-27 13:23:00</td>\n",
       "      <td>interesting question af subsidised af exists c...</td>\n",
       "      <td>Interesting question AF on your own or subsi...</td>\n",
       "      <td>39</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-27 17:46:00</td>\n",
       "      <td>im well prepared lose couldve insisted letting...</td>\n",
       "      <td>Im well prepared to lose it all now I couldv...</td>\n",
       "      <td>64</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-28 19:17:00</td>\n",
       "      <td>payment per ha per farmer im well used people ...</td>\n",
       "      <td>Payment is per ha not per farmer Im well use...</td>\n",
       "      <td>53</td>\n",
       "      <td>3.811321</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-28 19:48:00</td>\n",
       "      <td>great story ancient history move</td>\n",
       "      <td>Great story but ancient history Move on</td>\n",
       "      <td>9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-29 21:33:00</td>\n",
       "      <td>communism lol clown</td>\n",
       "      <td>Communism LOL  what a clown</td>\n",
       "      <td>9</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-31 00:43:00</td>\n",
       "      <td>sense entitlement scale really bizarre taxpaye...</td>\n",
       "      <td>Your sense of entitlement is off the scale  ...</td>\n",
       "      <td>26</td>\n",
       "      <td>4.730769</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-09-11 14:36:00</td>\n",
       "      <td>think eco 75 thereabouts reality itll depend m...</td>\n",
       "      <td>Think Eco is 75 or thereabouts but in realit...</td>\n",
       "      <td>37</td>\n",
       "      <td>4.081081</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-11-13 08:46:00</td>\n",
       "      <td>yes win win also help eco payment anc eco</td>\n",
       "      <td>Yes It win win it will also help with eco pa...</td>\n",
       "      <td>21</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-12 19:42:00</td>\n",
       "      <td>good investment buy commanage new cap 200 acre...</td>\n",
       "      <td>Is it a good investment to buy commanage with ...</td>\n",
       "      <td>16</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-12 19:49:00</td>\n",
       "      <td>reply makes perfect sense</td>\n",
       "      <td>Your reply makes perfect sense now that I th...</td>\n",
       "      <td>13</td>\n",
       "      <td>4.153846</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>New CAP</td>\n",
       "      <td>2021-10-12 19:53:00</td>\n",
       "      <td>makes perfect sense buy remaining shareholders...</td>\n",
       "      <td>It makes perfect sense if you think you can bu...</td>\n",
       "      <td>21</td>\n",
       "      <td>4.523810</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title                time  \\\n",
       "7    CAP Payments Reference Years 20002002 2017-08-27 18:57:00   \n",
       "8    CAP Payments Reference Years 20002002 2017-08-27 19:02:00   \n",
       "17                                Cap 2013 2013-07-23 18:57:00   \n",
       "28                                 New CAP 2021-10-26 19:43:00   \n",
       "31                                 New CAP 2021-10-26 19:47:00   \n",
       "33                                 New CAP 2021-10-26 20:00:00   \n",
       "62                              cap reform 2013-12-28 13:43:00   \n",
       "74                        New CAP for 2023 2022-03-16 17:16:00   \n",
       "75                        New CAP for 2023 2022-03-16 17:18:00   \n",
       "87                        New CAP for 2023 2022-03-16 20:38:00   \n",
       "90                        New CAP for 2023 2022-03-17 16:12:00   \n",
       "98                        New CAP for 2023 2022-03-18 20:13:00   \n",
       "99                                 New CAP 2021-10-27 12:59:00   \n",
       "101                                New CAP 2021-10-27 13:23:00   \n",
       "111                                New CAP 2021-10-27 17:46:00   \n",
       "136                                New CAP 2021-10-28 19:17:00   \n",
       "139                                New CAP 2021-10-28 19:48:00   \n",
       "143                                New CAP 2021-10-29 21:33:00   \n",
       "150                                New CAP 2021-10-31 00:43:00   \n",
       "159                                New CAP 2021-09-11 14:36:00   \n",
       "164                                New CAP 2021-11-13 08:46:00   \n",
       "172                                New CAP 2021-10-12 19:42:00   \n",
       "174                                New CAP 2021-10-12 19:49:00   \n",
       "175                                New CAP 2021-10-12 19:53:00   \n",
       "\n",
       "                                                  text  \\\n",
       "7               chosen privie information others lucky   \n",
       "8    afairm fairly well known going reference years...   \n",
       "17                                  good road frontage   \n",
       "28                           happy im farmer whats new   \n",
       "31   convergence heading right direction done thoug...   \n",
       "33   10k seems top new environmental scheme payment...   \n",
       "62   im guessing coincide sps 14 application period...   \n",
       "74   ok 25 figure using calc got saying 25 suckler ...   \n",
       "75   reference number ie best 3 years averagedlets ...   \n",
       "87                                        ah ok thanks   \n",
       "90   endainoz good truemy understanding based princ...   \n",
       "98   tree planting anyone got information many tree...   \n",
       "99   quick one agroforestry count towards eco schem...   \n",
       "101  interesting question af subsidised af exists c...   \n",
       "111  im well prepared lose couldve insisted letting...   \n",
       "136  payment per ha per farmer im well used people ...   \n",
       "139                   great story ancient history move   \n",
       "143                                communism lol clown   \n",
       "150  sense entitlement scale really bizarre taxpaye...   \n",
       "159  think eco 75 thereabouts reality itll depend m...   \n",
       "164          yes win win also help eco payment anc eco   \n",
       "172  good investment buy commanage new cap 200 acre...   \n",
       "174                          reply makes perfect sense   \n",
       "175  makes perfect sense buy remaining shareholders...   \n",
       "\n",
       "                                         text_original  word_count  avg_word  \\\n",
       "7    I would think the chosen few were privie to th...          16  4.687500   \n",
       "8      Afairm it was fairly well known there were g...          21  4.476190   \n",
       "17                                 Good road frontage            4  5.750000   \n",
       "28        Not happy but then Im a farmer so whats new           13  3.615385   \n",
       "31     Convergence heading in the right direction m...          53  4.698113   \n",
       "33   10k seems to be the top of the new environment...          87  4.321839   \n",
       "62     Im guessing it will coincide with the sps 14...          18  5.055556   \n",
       "74   OK so is the 25 figure youre using in that cal...          23  3.695652   \n",
       "75   Is it not the reference number ie your best 3 ...          38  5.026316   \n",
       "87                                        ah ok thanks           5  4.000000   \n",
       "90   Endainoz I think that would be to good to be t...          62  5.725806   \n",
       "98   Tree planting Anyone got any information on ho...          17  4.588235   \n",
       "99   Just quick one Will agroforestry count towards...          16  5.750000   \n",
       "101    Interesting question AF on your own or subsi...          39  4.846154   \n",
       "111    Im well prepared to lose it all now I couldv...          64  5.000000   \n",
       "136    Payment is per ha not per farmer Im well use...          53  3.811321   \n",
       "139            Great story but ancient history Move on           9  5.000000   \n",
       "143                        Communism LOL  what a clown           9  4.111111   \n",
       "150    Your sense of entitlement is off the scale  ...          26  4.730769   \n",
       "159    Think Eco is 75 or thereabouts but in realit...          37  4.081081   \n",
       "164    Yes It win win it will also help with eco pa...          21  3.571429   \n",
       "172  Is it a good investment to buy commanage with ...          16  4.250000   \n",
       "174    Your reply makes perfect sense now that I th...          13  4.153846   \n",
       "175  It makes perfect sense if you think you can bu...          21  4.523810   \n",
       "\n",
       "     stopwords  numeric_values  upper  sentiment  \n",
       "7            7               0      1   0.333333  \n",
       "8            8               0      0   0.700000  \n",
       "17           0               0      0   0.700000  \n",
       "28           4               0      0   0.468182  \n",
       "31          18               0      4   0.324416  \n",
       "33          38               0      4   0.347273  \n",
       "62           5               1      0   0.600000  \n",
       "74          11               2      1   0.500000  \n",
       "75          16               2      0   1.000000  \n",
       "87           0               0      0   0.350000  \n",
       "90          16               2      3   0.700000  \n",
       "98           8               0      0   0.500000  \n",
       "99           2               0      0   0.333333  \n",
       "101         14               0      2   0.500000  \n",
       "111         25               0      2   0.700000  \n",
       "136         17               3      1   0.400000  \n",
       "139          1               0      0   0.800000  \n",
       "143          2               0      1   0.800000  \n",
       "150         12               0      0   0.400000  \n",
       "159         15               0      1   0.500000  \n",
       "164          6               0      1   0.800000  \n",
       "172          6               1      1   0.418182  \n",
       "174          3               0      1   1.000000  \n",
       "175          9               0      0   0.466667  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_df.query(\"sentiment > 0.3 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative sentiment with values from ifa dataset as reference. \n",
    "\n",
    "Dataset in IFA are market briefings and articles describing facts or events on farming sector, it's clear that the sentiment should be neutral without any intention to translate / influence the reader or to induce an opinion. This give us a good reference of what neutral sentiment should be.\n",
    "\n",
    "On the other hand, boards.ie post and dicussions regarding CAP are opinions and discussion on the topic. As a referenced to produce thresholds to determine the sentiment of them thresholds calculated from IFA articles will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positve thestholds: \t(0.1,1]\n",
      "neutral: \t\t[-0.06,0.1]\n",
      "negatvie: \t\t[-1,-0.06)\n"
     ]
    }
   ],
   "source": [
    "negative_sentiment_threshold = round(market_price_df.sentiment.describe().reset_index().query(\"index == '25%'\")[\"sentiment\"].values[0],2)\n",
    "positive_sentiment_threshold = round(market_price_df.sentiment.describe().reset_index().query(\"index == '75%'\")[\"sentiment\"].values[0],2)\n",
    "\n",
    "print(f\"positve thestholds: \\t({positive_sentiment_threshold},1]\")\n",
    "print(f\"neutral: \\t\\t[{negative_sentiment_threshold},{positive_sentiment_threshold}]\")\n",
    "print(f\"negatvie: \\t\\t[-1,{negative_sentiment_threshold})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_class(sentiment:float):\n",
    "    if(sentiment > positive_sentiment_threshold):\n",
    "        return \"positive\"\n",
    "    elif(sentiment >= negative_sentiment_threshold):\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "\n",
    "cap_df['sentiment_class'] = cap_df['sentiment'].apply(lambda x: sentiment_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     74\n",
       "positive    69\n",
       "negative    34\n",
       "Name: sentiment_class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_df.sentiment_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"text\",\"word_count\",\"avg_word\",\"stopwords\",\"numeric_values\",\"upper\"]\n",
    "X = cap_df[columns]\n",
    "y = cap_df[\"sentiment_class\"]\n",
    "# Map class to integer 0, 1, 2\n",
    "y = y.apply(lambda x: ['negative', 'neutral', 'positive'].index(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP methods\n",
    "\n",
    "1. Count Vectorizer\n",
    "2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate an object cv by calling a method named as CountVectorizer()\n",
    "cv = CountVectorizer(max_features = 3000)\n",
    "\n",
    "# Train the dataset by calling a fit_transform() method\n",
    "X_fin = cv.fit_transform(X.text).toarray()\n",
    "\n",
    "# Display the rows and colums\n",
    "X_fin.shape\n",
    "\n",
    "# Instantiate an object model by calling a method MultinomialNB()\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Split the dataset into training and testing parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fin, y, test_size = 0.3)\n",
    "\n",
    "# Train the model by calling a method fit()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Call predict() method\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Predict R2: 0.967479674796748\n",
      "Test Data Predict R2: 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a mthod named as Cla\n",
    "train_r2 = model.score(X_train, y_train)\n",
    "test_r2 = model.score(X_test, y_test)\n",
    "\n",
    "# Display the results for train and test\n",
    "print(f\"Train Data Predict R2: {train_r2}\")\n",
    "print(f\"Test Data Predict R2: {test_r2}\")\n",
    "\n",
    "# Instantiate a mthod named as Cla\n",
    "cf_cv = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Predict R2: 0.7804878048780488\n",
      "Test Data Predict R2: 0.8703703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmsry\\anaconda3\\envs\\ca2_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rmsry\\anaconda3\\envs\\ca2_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rmsry\\anaconda3\\envs\\ca2_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create an object 'tf' by calling a method TfidfVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features = 3000)\n",
    "\n",
    "# Train the dataset by calling a method fit_tranform() \n",
    "X_tfidf = tfidf.fit_transform(X.text).toarray()\n",
    "\n",
    "# Instantiate an object model by calling a method MultinomialNB()\n",
    "model_tdidf = MultinomialNB()\n",
    "\n",
    "# Split the dataset into training and testing parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size = 0.3)\n",
    "\n",
    "# Train the model by calling a method fit()\n",
    "model_tdidf.fit(X_train, y_train)\n",
    "\n",
    "# Call predict() method\n",
    "y_pred = model_tdidf.predict(X_test)\n",
    "\n",
    "\n",
    "# Instantiate a mthod named as Cla\n",
    "train_r2 = model.score(X_train, y_train)\n",
    "test_r2 = model.score(X_test, y_test)\n",
    "\n",
    "# Display the results for train and test\n",
    "print(f\"Train Data Predict R2: {train_r2}\")\n",
    "print(f\"Test Data Predict R2: {test_r2}\")\n",
    "\n",
    "# Instantiate a mthod named as Cla\n",
    "cf_tdidf = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.31      0.35        13\n",
      "           1       0.48      0.52      0.50        21\n",
      "           2       0.43      0.45      0.44        20\n",
      "\n",
      "    accuracy                           0.44        54\n",
      "   macro avg       0.44      0.43      0.43        54\n",
      "weighted avg       0.44      0.44      0.44        54\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.59      0.38      0.47        26\n",
      "           2       0.30      0.65      0.41        17\n",
      "\n",
      "    accuracy                           0.39        54\n",
      "   macro avg       0.30      0.34      0.29        54\n",
      "weighted avg       0.38      0.39      0.35        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the values of an object cf\n",
    "print(cf_cv)\n",
    "# Display the values of an object cf\n",
    "print(cf_tdidf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c05728b5209f9bac5f2c8d5560e4b0392a10986a6d1a786d0ae84adef5e2173"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
